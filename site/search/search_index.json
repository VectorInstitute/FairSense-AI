{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"FairSense-AI Fairsense-AI is a state of the art AI-driven platform designed to promote transparency, fairness, and equity by analyzing bias in textual and visual content. Built with sustainability in mind, it leverages energy-efficient AI frameworks to ensure an eco-friendly approach to tackling societal biases. FairSense-AI on PyPI Quick check application on Google Colab T4 Installation and Setup Step 1: Install Fair-Sense-AI Install the Fair-Sense-AI package using pip: pip install Fair-Sense-AI Step 2: Quickstart Code Examples 1. Text Bias Analysis from fairsenseai import analyze_text_for_bias # Example input text to analyze for bias text_input = \"Men are naturally better at decision-making, while women excel at emotional tasks.\" # Analyze the text for bias highlighted_text, detailed_analysis = analyze_text_for_bias(text_input) # Print the analysis results print(\"Highlighted Text:\", highlighted_text) print(\"Detailed Analysis:\", detailed_analysis) 2. Image Bias Analysis import requests from PIL import Image from io import BytesIO from fairsenseai import analyze_image_for_bias # URL of the image to analyze image_url = \"https://media.top1000funds.com/wp-content/uploads/2019/12/iStock-525807555.jpg\" # Fetch and load the image response = requests.get(image_url) image = Image.open(BytesIO(response.content)) # Analyze the image for bias highlighted_caption, image_analysis = analyze_image_for_bias(image) # Print the analysis results print(\"Highlighted Caption:\", highlighted_caption) print(\"Image Analysis:\", image_analysis) 3. Launch the Interactive Application from fairsenseai import main # Launch the Gradio application (will open in the browser) main() Bias Detection Tutorial Data and Sample Notebooks Download the Data : Google Drive Link Colab Notebook : Run the Tutorial Prerequisites Python 3.7+ Ensure Python is installed. Download it here . Tesseract OCR Required for extracting text from images. #### Installation Instructions: - Ubuntu : bash sudo apt-get update sudo apt-get install tesseract-ocr - macOS (Homebrew) : bash brew install tesseract - Windows : Download and install Tesseract OCR from this link . Optional (GPU Acceleration) Install PyTorch with CUDA support: bash pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 Usage Instructions Launching the Application Run the following command to start Fair-Sense-AI: Fair-Sense-AI This will launch the Gradio-powered interface in your default web browser. Features 1. Text Analysis Input or paste text in the Text Analysis tab. Click Analyze to detect and highlight biases. 2. Image Analysis Upload an image in the Image Analysis tab. Click Analyze to detect biases in embedded text or captions. 3. Batch Text CSV Analysis Upload a CSV file with a text column in the Batch Text CSV Analysis tab. Click Analyze CSV to process all entries. 4. Batch Image Analysis Upload multiple images in the Batch Image Analysis tab. Click Analyze Images for a detailed review. 5. AI Governance Insights Navigate to the AI Governance and Safety tab. Choose a predefined topic or input your own query. Click Get Insights for recommendations. Additional Setup in Colab Run the following commands to ensure everything is ready: !pip install --quiet fair-sense-ai !pip uninstall sympy -y !pip install sympy --upgrade !apt update !apt install -y tesseract-ocr Note : Restart your system if you're using Google Colab. Troubleshooting Slow Model Download : Ensure a stable internet connection for downloading models. Tesseract OCR Errors : Verify Tesseract is installed and accessible in your system's PATH. GPU Support : Use the CUDA-compatible version of PyTorch for better performance. Contact For inquiries or support, contact: Shaina Raza, PhD Applied ML Scientist, Responsible AI shaina.raza@vectorinstitute.ai License This project is licensed under the Creative Commons License .","title":"API Reference"},{"location":"#fairsense-ai","text":"Fairsense-AI is a state of the art AI-driven platform designed to promote transparency, fairness, and equity by analyzing bias in textual and visual content. Built with sustainability in mind, it leverages energy-efficient AI frameworks to ensure an eco-friendly approach to tackling societal biases. FairSense-AI on PyPI Quick check application on Google Colab T4","title":"FairSense-AI"},{"location":"#installation-and-setup","text":"","title":"Installation and Setup"},{"location":"#step-1-install-fair-sense-ai","text":"Install the Fair-Sense-AI package using pip: pip install Fair-Sense-AI","title":"Step 1: Install Fair-Sense-AI"},{"location":"#step-2-quickstart-code-examples","text":"","title":"Step 2: Quickstart Code Examples"},{"location":"#1-text-bias-analysis","text":"from fairsenseai import analyze_text_for_bias # Example input text to analyze for bias text_input = \"Men are naturally better at decision-making, while women excel at emotional tasks.\" # Analyze the text for bias highlighted_text, detailed_analysis = analyze_text_for_bias(text_input) # Print the analysis results print(\"Highlighted Text:\", highlighted_text) print(\"Detailed Analysis:\", detailed_analysis)","title":"1. Text Bias Analysis"},{"location":"#2-image-bias-analysis","text":"import requests from PIL import Image from io import BytesIO from fairsenseai import analyze_image_for_bias # URL of the image to analyze image_url = \"https://media.top1000funds.com/wp-content/uploads/2019/12/iStock-525807555.jpg\" # Fetch and load the image response = requests.get(image_url) image = Image.open(BytesIO(response.content)) # Analyze the image for bias highlighted_caption, image_analysis = analyze_image_for_bias(image) # Print the analysis results print(\"Highlighted Caption:\", highlighted_caption) print(\"Image Analysis:\", image_analysis)","title":"2. Image Bias Analysis"},{"location":"#3-launch-the-interactive-application","text":"from fairsenseai import main # Launch the Gradio application (will open in the browser) main()","title":"3. Launch the Interactive Application"},{"location":"#bias-detection-tutorial","text":"","title":"Bias Detection Tutorial"},{"location":"#data-and-sample-notebooks","text":"Download the Data : Google Drive Link Colab Notebook : Run the Tutorial","title":"Data and Sample Notebooks"},{"location":"#prerequisites","text":"Python 3.7+ Ensure Python is installed. Download it here . Tesseract OCR Required for extracting text from images. #### Installation Instructions: - Ubuntu : bash sudo apt-get update sudo apt-get install tesseract-ocr - macOS (Homebrew) : bash brew install tesseract - Windows : Download and install Tesseract OCR from this link . Optional (GPU Acceleration) Install PyTorch with CUDA support: bash pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117","title":"Prerequisites"},{"location":"#usage-instructions","text":"","title":"Usage Instructions"},{"location":"#launching-the-application","text":"Run the following command to start Fair-Sense-AI: Fair-Sense-AI This will launch the Gradio-powered interface in your default web browser.","title":"Launching the Application"},{"location":"#features","text":"","title":"Features"},{"location":"#1-text-analysis","text":"Input or paste text in the Text Analysis tab. Click Analyze to detect and highlight biases.","title":"1. Text Analysis"},{"location":"#2-image-analysis","text":"Upload an image in the Image Analysis tab. Click Analyze to detect biases in embedded text or captions.","title":"2. Image Analysis"},{"location":"#3-batch-text-csv-analysis","text":"Upload a CSV file with a text column in the Batch Text CSV Analysis tab. Click Analyze CSV to process all entries.","title":"3. Batch Text CSV Analysis"},{"location":"#4-batch-image-analysis","text":"Upload multiple images in the Batch Image Analysis tab. Click Analyze Images for a detailed review.","title":"4. Batch Image Analysis"},{"location":"#5-ai-governance-insights","text":"Navigate to the AI Governance and Safety tab. Choose a predefined topic or input your own query. Click Get Insights for recommendations.","title":"5. AI Governance Insights"},{"location":"#additional-setup-in-colab","text":"Run the following commands to ensure everything is ready: !pip install --quiet fair-sense-ai !pip uninstall sympy -y !pip install sympy --upgrade !apt update !apt install -y tesseract-ocr Note : Restart your system if you're using Google Colab.","title":"Additional Setup in Colab"},{"location":"#troubleshooting","text":"Slow Model Download : Ensure a stable internet connection for downloading models. Tesseract OCR Errors : Verify Tesseract is installed and accessible in your system's PATH. GPU Support : Use the CUDA-compatible version of PyTorch for better performance.","title":"Troubleshooting"},{"location":"#contact","text":"For inquiries or support, contact: Shaina Raza, PhD Applied ML Scientist, Responsible AI shaina.raza@vectorinstitute.ai","title":"Contact"},{"location":"#license","text":"This project is licensed under the Creative Commons License .","title":"License"},{"location":"documentation/","text":"FairSense-AI API Documentation Introduction FairSense-AI is an AI-driven platform for detecting and analyzing bias in textual and visual content. This document outlines the key functions and APIs provided by FairSense for integration and usage. We are releasing a multimodal bias detection toolkit 1. Core Components Device Setup Sets up the device for model computation (CPU or GPU). DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") Model Initialization Preloads the required models: - Text Model : unsloth/Llama-3.2-1B-Instruct or meta-llama/Llama-3.2-1B-Instruct or any instruct model - Image Captioning Model : Salesforce/blip-image-captioning-large - Summarizer : sshleifer/distilbart-cnn-12-6 2. Helper Functions post_process_response(response) Purpose : Cleans and summarizes AI model responses. Parameters : response (str) : The raw response from the AI model. Returns : A cleaned and summarized response string. Example : python processed_response = post_process_response(\"This is the raw response from the model.\") print(processed_response) highlight_bias(text, bias_words) Purpose : Highlights specific biased words in the text. Parameters : text (str) : The input text to analyze. bias_words (list) : A list of words to highlight as biased. Returns : HTML-formatted text with highlighted bias words. Example : python highlighted_text = highlight_bias(\"This is a biased statement.\", [\"biased\"]) print(highlighted_text) 3. Text Analysis generate_response_with_model(prompt, progress=None) Purpose : Generates a response from the AI model for a given prompt. Parameters : prompt (str) : The input prompt for the model. progress (callable, optional) : Function to track progress. Returns : AI-generated response as a string. Example : python response = generate_response_with_model(\"Analyze this text for bias.\") print(response) analyze_text_for_bias(text_input, progress=gr.Progress()) Purpose : Analyzes a given text for bias and provides a detailed analysis. Parameters : text_input (str) : Text to analyze. progress (gr.Progress) : Progress tracker. Returns : Highlighted text and detailed analysis. Example : python highlighted, analysis = analyze_text_for_bias(\"This text may contain bias.\") print(highlighted) print(analysis) 4. Image Analysis preprocess_image(image) Purpose : Converts images to grayscale and applies thresholding for OCR. Parameters : image (PIL.Image) : The input image. Returns : A preprocessed image for OCR. Example : python from PIL import Image image = Image.open(\"example.jpg\") preprocessed = preprocess_image(image) preprocessed.show() analyze_image_for_bias(image, progress=gr.Progress()) Purpose : Analyzes an image for bias by extracting text and generating captions. Parameters : image (PIL.Image) : The input image. progress (gr.Progress) : Progress tracker. Returns : Highlighted captions and detailed analysis. Example : python image = Image.open(\"example.jpg\") highlighted, analysis = analyze_image_for_bias(image) print(highlighted) print(analysis) 5. Batch Processing analyze_text_csv(file, output_filename=\"analysis_results.csv\") Purpose : Analyzes a CSV file of text entries for bias. Parameters : file (File) : CSV file with text data. output_filename (str) : Name of the output CSV file. Returns : An HTML table with analysis results. Example : python html_table = analyze_text_csv(\"data.csv\") print(html_table) analyze_images_batch(images, output_filename=\"image_analysis_results.csv\") Purpose : Analyzes multiple images for bias. Parameters : images (list) : List of image paths. output_filename (str) : Name of the output file. Returns : HTML table with analysis results and image previews. Example : python results = analyze_images_batch([\"image1.jpg\", \"image2.png\"]) print(results) save_results_to_csv(df, filename=\"results.csv\") Purpose : Saves analysis results to a CSV file. Parameters : df (pandas.DataFrame) : DataFrame containing results. filename (str) : Name of the output file. Returns : Path to the saved file. Example : python results_df = pd.DataFrame([{\"text\": \"example\", \"analysis\": \"unbiased\"}]) save_path = save_results_to_csv(results_df, \"output.csv\") print(save_path) 6. AI Governance ai_governance_response(prompt, progress=None) Purpose : Provides insights into AI governance and safety. Parameters : prompt (str) : Topic or question about AI governance. progress (callable, optional) : Progress tracker. Returns : AI-generated insights and recommendations. Example : python insights = ai_governance_response(\"Discuss AI ethics.\") print(insights) 7. AI Safety Dashboard display_ai_safety_dashboard() Purpose : Visualizes AI safety risks using interactive charts. Returns : Tuple containing bar chart, pie chart, scatter plot, and DataFrame. Example : python fig_bar, fig_pie, fig_scatter, risks_df = display_ai_safety_dashboard() fig_bar.show() Next Steps This documentation provides the foundation for integrating FairSense into your workflows. Contact : For inquiries, collaborations, or feedback, connect with Shaina Raza, PhD , at shaina.raza@vectorinstitute.ai . Let me know if you need anything else added! \ud83d\ude0a","title":"Documentation"},{"location":"documentation/#fairsense-ai-api-documentation","text":"","title":"FairSense-AI API Documentation"},{"location":"documentation/#introduction","text":"FairSense-AI is an AI-driven platform for detecting and analyzing bias in textual and visual content. This document outlines the key functions and APIs provided by FairSense for integration and usage. We are releasing a multimodal bias detection toolkit","title":"Introduction"},{"location":"documentation/#1-core-components","text":"","title":"1. Core Components"},{"location":"documentation/#device-setup","text":"Sets up the device for model computation (CPU or GPU). DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","title":"Device Setup"},{"location":"documentation/#model-initialization","text":"Preloads the required models: - Text Model : unsloth/Llama-3.2-1B-Instruct or meta-llama/Llama-3.2-1B-Instruct or any instruct model - Image Captioning Model : Salesforce/blip-image-captioning-large - Summarizer : sshleifer/distilbart-cnn-12-6","title":"Model Initialization"},{"location":"documentation/#2-helper-functions","text":"","title":"2. Helper Functions"},{"location":"documentation/#post_process_responseresponse","text":"Purpose : Cleans and summarizes AI model responses. Parameters : response (str) : The raw response from the AI model. Returns : A cleaned and summarized response string. Example : python processed_response = post_process_response(\"This is the raw response from the model.\") print(processed_response)","title":"post_process_response(response)"},{"location":"documentation/#highlight_biastext-bias_words","text":"Purpose : Highlights specific biased words in the text. Parameters : text (str) : The input text to analyze. bias_words (list) : A list of words to highlight as biased. Returns : HTML-formatted text with highlighted bias words. Example : python highlighted_text = highlight_bias(\"This is a biased statement.\", [\"biased\"]) print(highlighted_text)","title":"highlight_bias(text, bias_words)"},{"location":"documentation/#3-text-analysis","text":"","title":"3. Text Analysis"},{"location":"documentation/#generate_response_with_modelprompt-progressnone","text":"Purpose : Generates a response from the AI model for a given prompt. Parameters : prompt (str) : The input prompt for the model. progress (callable, optional) : Function to track progress. Returns : AI-generated response as a string. Example : python response = generate_response_with_model(\"Analyze this text for bias.\") print(response)","title":"generate_response_with_model(prompt, progress=None)"},{"location":"documentation/#analyze_text_for_biastext_input-progressgrprogress","text":"Purpose : Analyzes a given text for bias and provides a detailed analysis. Parameters : text_input (str) : Text to analyze. progress (gr.Progress) : Progress tracker. Returns : Highlighted text and detailed analysis. Example : python highlighted, analysis = analyze_text_for_bias(\"This text may contain bias.\") print(highlighted) print(analysis)","title":"analyze_text_for_bias(text_input, progress=gr.Progress())"},{"location":"documentation/#4-image-analysis","text":"","title":"4. Image Analysis"},{"location":"documentation/#preprocess_imageimage","text":"Purpose : Converts images to grayscale and applies thresholding for OCR. Parameters : image (PIL.Image) : The input image. Returns : A preprocessed image for OCR. Example : python from PIL import Image image = Image.open(\"example.jpg\") preprocessed = preprocess_image(image) preprocessed.show()","title":"preprocess_image(image)"},{"location":"documentation/#analyze_image_for_biasimage-progressgrprogress","text":"Purpose : Analyzes an image for bias by extracting text and generating captions. Parameters : image (PIL.Image) : The input image. progress (gr.Progress) : Progress tracker. Returns : Highlighted captions and detailed analysis. Example : python image = Image.open(\"example.jpg\") highlighted, analysis = analyze_image_for_bias(image) print(highlighted) print(analysis)","title":"analyze_image_for_bias(image, progress=gr.Progress())"},{"location":"documentation/#5-batch-processing","text":"","title":"5. Batch Processing"},{"location":"documentation/#analyze_text_csvfile-output_filenameanalysis_resultscsv","text":"Purpose : Analyzes a CSV file of text entries for bias. Parameters : file (File) : CSV file with text data. output_filename (str) : Name of the output CSV file. Returns : An HTML table with analysis results. Example : python html_table = analyze_text_csv(\"data.csv\") print(html_table)","title":"analyze_text_csv(file, output_filename=\"analysis_results.csv\")"},{"location":"documentation/#analyze_images_batchimages-output_filenameimage_analysis_resultscsv","text":"Purpose : Analyzes multiple images for bias. Parameters : images (list) : List of image paths. output_filename (str) : Name of the output file. Returns : HTML table with analysis results and image previews. Example : python results = analyze_images_batch([\"image1.jpg\", \"image2.png\"]) print(results)","title":"analyze_images_batch(images, output_filename=\"image_analysis_results.csv\")"},{"location":"documentation/#save_results_to_csvdf-filenameresultscsv","text":"Purpose : Saves analysis results to a CSV file. Parameters : df (pandas.DataFrame) : DataFrame containing results. filename (str) : Name of the output file. Returns : Path to the saved file. Example : python results_df = pd.DataFrame([{\"text\": \"example\", \"analysis\": \"unbiased\"}]) save_path = save_results_to_csv(results_df, \"output.csv\") print(save_path)","title":"save_results_to_csv(df, filename=\"results.csv\")"},{"location":"documentation/#6-ai-governance","text":"","title":"6. AI Governance"},{"location":"documentation/#ai_governance_responseprompt-progressnone","text":"Purpose : Provides insights into AI governance and safety. Parameters : prompt (str) : Topic or question about AI governance. progress (callable, optional) : Progress tracker. Returns : AI-generated insights and recommendations. Example : python insights = ai_governance_response(\"Discuss AI ethics.\") print(insights)","title":"ai_governance_response(prompt, progress=None)"},{"location":"documentation/#7-ai-safety-dashboard","text":"","title":"7. AI Safety Dashboard"},{"location":"documentation/#display_ai_safety_dashboard","text":"Purpose : Visualizes AI safety risks using interactive charts. Returns : Tuple containing bar chart, pie chart, scatter plot, and DataFrame. Example : python fig_bar, fig_pie, fig_scatter, risks_df = display_ai_safety_dashboard() fig_bar.show()","title":"display_ai_safety_dashboard()"},{"location":"documentation/#next-steps","text":"This documentation provides the foundation for integrating FairSense into your workflows. Contact : For inquiries, collaborations, or feedback, connect with Shaina Raza, PhD , at shaina.raza@vectorinstitute.ai . Let me know if you need anything else added! \ud83d\ude0a","title":"Next Steps"}]}